{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "# å°‘é‡æ ·æœ¬ç¤ºä¾‹çš„æç¤ºè¯æ¨¡æ¿\n",
    "- FewShotPromptTemplate:ä¸PromptTemplateä¸€èµ·ä½¿ç”¨\n",
    "- FewShotChatMessagePromptTemplate:ä¸ChatPromptTemplateä¸€èµ·ä½¿ç”¨\n",
    "- Example selectors(ç¤ºä¾‹é€‰æ‹©å™¨):"
   ],
   "id": "cfb80be3387e4c47"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1ã€ FewShotPromptTemplateçš„ä½¿ç”¨\n",
   "id": "b6d4f09503c5b2b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:53:02.837361Z",
     "start_time": "2025-09-28T16:52:54.905394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ä¸¾ä¾‹1:æœªæä¾›ç¤ºä¾‹çš„æƒ…å†µ\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY1\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\",\n",
    "                        temperature=0.4)\n",
    "res = chat_model.invoke(\"2 ğŸ¦œ 9æ˜¯å¤šå°‘?\")\n",
    "print(res.content)"
   ],
   "id": "b74ce94b2e1dfc99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ğŸ¦œ 9 çš„æ„æ€å¯èƒ½ä¸å¤ªæ˜ç¡®ã€‚å¦‚æœä½ æ˜¯åœ¨é—®æ•°å­¦è¿ç®—ï¼Œé€šå¸¸æˆ‘ä»¬ä¼šç”¨åŠ ã€å‡ã€ä¹˜ã€é™¤ç­‰ç¬¦å·ã€‚å¦‚æœä½ èƒ½æä¾›æ›´å¤šçš„ä¸Šä¸‹æ–‡æˆ–è¯´æ˜ï¼Œæˆ‘ä¼šæ›´å¥½åœ°å¸®åŠ©ä½ ã€‚\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T17:09:32.403731Z",
     "start_time": "2025-09-28T17:09:30.049158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ä¸¾ä¾‹2ï¼šä½¿ç”¨FewShotPromptTemplateï¼Œæä¾›å°‘é‡ç¤ºä¾‹\n",
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY1\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\",\n",
    "                        temperature=0.4)\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªPromptTemplateçš„å®ä¾‹\n",
    "example_prompt = PromptTemplate.from_template(\n",
    "\ttemplate=\"inputï¼š{input}\\noutputï¼š{output}\\n\",\n",
    ")\n",
    "# æä¾›ä¸€äº›ç¤ºä¾‹\n",
    "examples = [\n",
    "\t{\"input\": \"åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·\", \"output\": \"åŒ—äº¬å¸‚\"},\n",
    "\t{\"input\": \"å—äº¬ä¸‹é›¨å—\", \"output\": \"å—äº¬å¸‚\"},\n",
    "\t{\"input\": \"æ­¦æ±‰çƒ­å—\", \"output\": \"æ­¦æ±‰å¸‚\"}\n",
    "]\n",
    "\n",
    "# åˆ›å»ºFewShotPromptTemplateçš„å®ä¾‹\n",
    "few_short_template = FewShotPromptTemplate(\n",
    "\texample_prompt=example_prompt,\n",
    "\texamples=examples,\n",
    "\tsuffix=\"inputï¼š{input}\\noutput\\n\",  #å£°æ˜åœ¨ç¤ºä¾‹åé¢çš„æç¤ºè¯æ¨¡æ¿\n",
    "\tinput_variables=[\"input\"],  # å£°æ˜éœ€è¦å¡«å……çš„å˜é‡\n",
    ")\n",
    "\n",
    "# ç»“åˆå¤§æ¨¡å‹ï¼Œç”Ÿæˆå†…å®¹\n",
    "response = chat_model.invoke(few_short_template.invoke(\n",
    "\t{\n",
    "\t\t\"input\": \"ä¸Šæµ·å¤©æ°”æ€ä¹ˆæ ·\"\n",
    "\t}\n",
    "))\n",
    "print(response.content)\n",
    "print(response)"
   ],
   "id": "cc9b34058a5eff63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï¼šä¸Šæµ·å¸‚\n",
      "content='ï¼šä¸Šæµ·å¸‚' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 48, 'total_tokens': 52, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_efad92c60b', 'id': 'chatcmpl-CKpBqywhvxSlL7Yo12tKK0jBkGb8C', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--bf83c444-30e9-44dd-8696-0a673846c776-0' usage_metadata={'input_tokens': 48, 'output_tokens': 4, 'total_tokens': 52, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T17:10:51.974599Z",
     "start_time": "2025-09-28T17:10:49.695384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ä¸¾ä¾‹3\n",
    "\n",
    "#1ã€åˆ›å»ºæç¤ºæ¨¡æ¿\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# åˆ›å»ºæç¤ºæ¨¡æ¿ï¼Œé…ç½®ä¸€ä¸ªæç¤ºæ¨¡æ¿ï¼Œå°†ä¸€ä¸ªç¤ºä¾‹æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²\n",
    "prompt_template = \"ä½ æ˜¯ä¸€ä¸ªæ•°å­¦ä¸“å®¶,ç®—å¼ï¼š {input} å€¼ï¼š {output} ä½¿ç”¨ï¼š {description} \"\n",
    "# è¿™æ˜¯ä¸€ä¸ªæç¤ºæ¨¡æ¿ï¼Œç”¨äºè®¾ç½®æ¯ä¸ªç¤ºä¾‹çš„æ ¼å¼\n",
    "prompt_sample = PromptTemplate.from_template(prompt_template)\n",
    "#2ã€æä¾›ç¤ºä¾‹\n",
    "examples = [\n",
    "\t{\"input\": \"2+2\", \"output\": \"4\", \"description\": \"åŠ æ³•è¿ç®—\"},\n",
    "\t{\"input\": \"5-2\", \"output\": \"3\", \"description\": \"å‡æ³•è¿ç®—\"},\n",
    "]\n",
    "#3ã€åˆ›å»ºä¸€ä¸ªFewShotPromptTemplateå¯¹è±¡\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "\texamples=examples,\n",
    "\texample_prompt=prompt_sample,\n",
    "\tsuffix=\"ä½ æ˜¯ä¸€ä¸ªæ•°å­¦ä¸“å®¶,ç®—å¼: {input} å€¼: {output}\",\n",
    "\tinput_variables=[\"input\", \"output\"]\n",
    ")\n",
    "print(prompt.invoke({\"input\": \"2*5\", \"output\": \"10\"}))\n",
    "#4ã€åˆå§‹åŒ–å¤§æ¨¡å‹ï¼Œç„¶åè°ƒç”¨\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY1\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "result = chat_model.invoke(prompt.invoke({\"input\": \"2*5\", \"output\": \"10\"}))\n",
    "print(result.content)  # ä½¿ç”¨: ä¹˜æ³•è¿ç®—"
   ],
   "id": "e839ab6a171af483",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='ä½ æ˜¯ä¸€ä¸ªæ•°å­¦ä¸“å®¶,ç®—å¼ï¼š 2+2 å€¼ï¼š 4 ä½¿ç”¨ï¼š åŠ æ³•è¿ç®— \\n\\nä½ æ˜¯ä¸€ä¸ªæ•°å­¦ä¸“å®¶,ç®—å¼ï¼š 5-2 å€¼ï¼š 3 ä½¿ç”¨ï¼š å‡æ³•è¿ç®— \\n\\nä½ æ˜¯ä¸€ä¸ªæ•°å­¦ä¸“å®¶,ç®—å¼: 2*5 å€¼: 10'\n",
      "ä½¿ç”¨ï¼š ä¹˜æ³•è¿ç®— \n",
      "\n",
      "ä½ æ˜¯ä¸€ä¸ªæ•°å­¦ä¸“å®¶,ç®—å¼: 15/3 å€¼: 5 ä½¿ç”¨ï¼š é™¤æ³•è¿ç®— \n",
      "\n",
      "å¦‚æœæœ‰å…¶ä»–æ•°å­¦é—®é¢˜æˆ–ç®—å¼éœ€è¦è®¡ç®—ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2ã€FewShotChatMessagePromptTemplateçš„ä½¿ç”¨",
   "id": "9db851ac0333d055"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T14:08:11.950976Z",
     "start_time": "2025-09-29T14:08:11.930955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ä¸¾ä¾‹1\n",
    "from langchain.prompts import (FewShotChatMessagePromptTemplate,\n",
    "                               ChatPromptTemplate\n",
    "                               )\n",
    "\n",
    "# 1.ç¤ºä¾‹æ¶ˆæ¯æ ¼å¼\n",
    "examples = [\n",
    "\t{\"input\": \"1+1ç­‰äºå‡ ï¼Ÿ\", \"output\": \"1+1ç­‰äº2\"},\n",
    "\t{\"input\": \"æ³•å›½çš„é¦–éƒ½æ˜¯ï¼Ÿ\", \"output\": \"å·´é»\"}\n",
    "]\n",
    "\n",
    "# 2.å®šä¹‰ç¤ºä¾‹çš„æ¶ˆæ¯æ ¼å¼æç¤ºè¯æ¨¡ç‰ˆ\n",
    "msg_example_prompt = ChatPromptTemplate.from_messages([\n",
    "\t(\"human\", \"{input}\"),\n",
    "\t(\"ai\", \"{output}\"),\n",
    "])\n",
    "\n",
    "# 3.å®šä¹‰FewShotChatMessagePromptTemplateå¯¹è±¡\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "\texample_prompt=msg_example_prompt,\n",
    "\texamples=examples\n",
    ")\n",
    "\n",
    "# 4.è¾“å‡ºæ ¼å¼åŒ–åçš„æ¶ˆæ¯\n",
    "print(few_shot_prompt.format())"
   ],
   "id": "44e33d7f7d16138a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 1+1ç­‰äºå‡ ï¼Ÿ\n",
      "AI: 1+1ç­‰äº2\n",
      "Human: æ³•å›½çš„é¦–éƒ½æ˜¯ï¼Ÿ\n",
      "AI: å·´é»\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T14:14:16.713116Z",
     "start_time": "2025-09-29T14:13:58.721506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ä¸¾ä¾‹2\n",
    "# 1.å¯¼å…¥ç›¸å…³åŒ…\n",
    "from langchain_core.prompts import (FewShotChatMessagePromptTemplate,\n",
    "                                    ChatPromptTemplate)\n",
    "\n",
    "# 2.å®šä¹‰ç¤ºä¾‹ç»„\n",
    "examples = [\n",
    "\t{\"input\": \"2ğŸ¦œ2\", \"output\": \"4\"},\n",
    "\t{\"input\": \"2ğŸ¦œ3\", \"output\": \"8\"},\n",
    "]\n",
    "# 3.å®šä¹‰ç¤ºä¾‹çš„æ¶ˆæ¯æ ¼å¼æç¤ºè¯æ¨¡ç‰ˆ\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "\t('human', '{input} æ˜¯å¤šå°‘?'),\n",
    "\t('ai', '{output}')\n",
    "])\n",
    "# 4.å®šä¹‰FewShotChatMessagePromptTemplateå¯¹è±¡\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "\texamples=examples,  # ç¤ºä¾‹ç»„\n",
    "\texample_prompt=example_prompt,  # ç¤ºä¾‹æç¤ºè¯è¯æ¨¡ç‰ˆ\n",
    ")\n",
    "# 5.è¾“å‡ºå®Œæ•´æç¤ºè¯çš„æ¶ˆæ¯æ¨¡ç‰ˆ\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "\t[\n",
    "\t\t('system', 'ä½ æ˜¯ä¸€ä¸ªæ•°å­¦å¥‡æ‰'),\n",
    "\t\tfew_shot_prompt,\n",
    "\t\t('human', '{input}'),\n",
    "\t]\n",
    ")\n",
    "#6.æä¾›å¤§æ¨¡å‹\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY1\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\",\n",
    "                        temperature=0.4)\n",
    "chat_model.invoke(final_prompt.invoke(input=\"2ğŸ¦œ4\")).content"
   ],
   "id": "d394a596869f2dbe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2ğŸ¦œ4 ç­‰äº 16ã€‚'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3ã€Example selectors(ç¤ºä¾‹é€‰æ‹©å™¨)",
   "id": "754abd8d4a02cf84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ä¸¾ä¾‹1\n",
    "# 1.å¯¼å…¥ç›¸å…³åŒ…\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# 2.å®šä¹‰åµŒå…¥æ¨¡å‹\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY1\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "embeddings_model = OpenAIEmbeddings(\n",
    "\tmodel=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "# 3.å®šä¹‰ç¤ºä¾‹ç»„\n",
    "examples = [\n",
    "\t{\n",
    "\t\t\"question\": \"è°æ´»å¾—æ›´ä¹…ï¼Œç©†ç½•é»˜å¾·Â·é˜¿é‡Œè¿˜æ˜¯è‰¾ä¼¦Â·å›¾çµ?\",\n",
    "\t\t\"answer\": \"\"\"\n",
    "æ¥ä¸‹æ¥è¿˜éœ€è¦é—®ä»€ä¹ˆé—®é¢˜å—ï¼Ÿ\n",
    "è¿½é—®ï¼šç©†ç½•é»˜å¾·Â·é˜¿é‡Œå»ä¸–æ—¶å¤šå¤§å¹´çºªï¼Ÿ\n",
    "ä¸­é—´ç­”æ¡ˆï¼šç©†ç½•é»˜å¾·Â·é˜¿é‡Œå»ä¸–æ—¶äº«å¹´74å²ã€‚\n",
    "\"\"\",\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"question\": \"craigslistçš„åˆ›å§‹äººæ˜¯ä»€ä¹ˆæ—¶å€™å‡ºç”Ÿçš„ï¼Ÿ\",\n",
    "\t\t\"answer\": \"\"\"\n",
    "æ¥ä¸‹æ¥è¿˜éœ€è¦é—®ä»€ä¹ˆé—®é¢˜å—ï¼Ÿ\n",
    "è¿½é—®ï¼šè°æ˜¯craigslistçš„åˆ›å§‹äººï¼Ÿ\n",
    "ä¸­çº§ç­”æ¡ˆï¼šCraigslistæ˜¯ç”±å…‹é›·æ ¼Â·çº½é©¬å…‹åˆ›ç«‹çš„ã€‚\n",
    "\"\"\",\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"question\": \"è°æ˜¯ä¹”æ²»Â·åç››é¡¿çš„å¤–ç¥–çˆ¶ï¼Ÿ\",\n",
    "\t\t\"answer\": \"\"\"\n",
    "æ¥ä¸‹æ¥è¿˜éœ€è¦é—®ä»€ä¹ˆé—®é¢˜å—ï¼Ÿ\n",
    "è¿½é—®ï¼šè°æ˜¯ä¹”æ²»Â·åç››é¡¿çš„æ¯äº²ï¼Ÿ\n",
    "ä¸­é—´ç­”æ¡ˆï¼šä¹”æ²»Â·åç››é¡¿çš„æ¯äº²æ˜¯ç›ä¸½Â·é²å°”Â·åç››é¡¿ã€‚\n",
    "\"\"\",\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"question\": \"ã€Šå¤§ç™½é²¨ã€‹å’Œã€Šçš‡å®¶èµŒåœºã€‹çš„å¯¼æ¼”éƒ½æ¥è‡ªåŒä¸€ä¸ªå›½å®¶å—ï¼Ÿ\",\n",
    "\t\t\"answer\": \"\"\"\n",
    "æ¥ä¸‹æ¥è¿˜éœ€è¦é—®ä»€ä¹ˆé—®é¢˜å—ï¼Ÿ\n",
    "è¿½é—®ï¼šã€Šå¤§ç™½é²¨ã€‹çš„å¯¼æ¼”æ˜¯è°ï¼Ÿ\n",
    "ä¸­çº§ç­”æ¡ˆï¼šã€Šå¤§ç™½é²¨ã€‹çš„å¯¼æ¼”æ˜¯å²è’‚æ–‡Â·æ–¯çš®å°”ä¼¯æ ¼ã€‚\n",
    "\"\"\",\n",
    "\t},\n",
    "]\n",
    "# 4.å®šä¹‰ç¤ºä¾‹é€‰æ‹©å™¨\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "\t# è¿™æ˜¯å¯ä¾›é€‰æ‹©çš„ç¤ºä¾‹åˆ—è¡¨\n",
    "\texamples,\n",
    "\t# è¿™æ˜¯ç”¨äºç”ŸæˆåµŒå…¥çš„åµŒå…¥ç±»ï¼Œç”¨äºè¡¡é‡è¯­ä¹‰ç›¸ä¼¼æ€§\n",
    "\tembeddings_model,\n",
    "\t# è¿™æ˜¯ç”¨äºå­˜å‚¨åµŒå…¥å¹¶è¿›è¡Œç›¸ä¼¼æ€§æœç´¢çš„ VectorStore ç±»\n",
    "\tChroma,\n",
    "\t# è¿™æ˜¯è¦ç”Ÿæˆçš„ç¤ºä¾‹æ•°é‡\n",
    "\tk=1,\n",
    ")\n",
    "# é€‰æ‹©ä¸è¾“å…¥æœ€ç›¸ä¼¼çš„ç¤ºä¾‹\n",
    "question = \"ç›ä¸½Â·é²å°”Â·åç››é¡¿çš„çˆ¶äº²æ˜¯è°?\"\n",
    "selected_examples = example_selector.select_examples({\"question\": question})\n",
    "print(f\"ä¸è¾“å…¥æœ€ç›¸ä¼¼çš„ç¤ºä¾‹ï¼š{selected_examples}\")\n",
    "# for example in selected_examples:\n",
    "# print(\"\\n\")\n",
    "# for k, v in example.items():\n",
    "# print(f\"{k}: {v}\")"
   ],
   "id": "521f0c13ae8e7e9a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
