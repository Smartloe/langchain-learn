{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "# å°‘é‡æ ·æœ¬ç¤ºä¾‹çš„æç¤ºè¯æ¨¡æ¿\n",
    "- FewShotPromptTemplate:ä¸PromptTemplateä¸€èµ·ä½¿ç”¨\n",
    "- FewShotChatMessagePromptTemplate:ä¸ChatPromptTemplateä¸€èµ·ä½¿ç”¨\n",
    "- Example selectors(ç¤ºä¾‹é€‰æ‹©å™¨):"
   ],
   "id": "cfb80be3387e4c47"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1ã€ FewShotPromptTemplateçš„ä½¿ç”¨\n",
   "id": "b6d4f09503c5b2b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:53:02.837361Z",
     "start_time": "2025-09-28T16:52:54.905394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ä¸¾ä¾‹1:æœªæä¾›ç¤ºä¾‹çš„æƒ…å†µ\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY1\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\",\n",
    "                        temperature=0.4)\n",
    "res = chat_model.invoke(\"2 ğŸ¦œ 9æ˜¯å¤šå°‘?\")\n",
    "print(res.content)"
   ],
   "id": "b74ce94b2e1dfc99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ğŸ¦œ 9 çš„æ„æ€å¯èƒ½ä¸å¤ªæ˜ç¡®ã€‚å¦‚æœä½ æ˜¯åœ¨é—®æ•°å­¦è¿ç®—ï¼Œé€šå¸¸æˆ‘ä»¬ä¼šç”¨åŠ ã€å‡ã€ä¹˜ã€é™¤ç­‰ç¬¦å·ã€‚å¦‚æœä½ èƒ½æä¾›æ›´å¤šçš„ä¸Šä¸‹æ–‡æˆ–è¯´æ˜ï¼Œæˆ‘ä¼šæ›´å¥½åœ°å¸®åŠ©ä½ ã€‚\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T17:09:32.403731Z",
     "start_time": "2025-09-28T17:09:30.049158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ä¸¾ä¾‹2ï¼šä½¿ç”¨FewShotPromptTemplateï¼Œæä¾›å°‘é‡ç¤ºä¾‹\n",
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY1\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\",\n",
    "                        temperature=0.4)\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªPromptTemplateçš„å®ä¾‹\n",
    "example_prompt = PromptTemplate.from_template(\n",
    "\ttemplate=\"inputï¼š{input}\\noutputï¼š{output}\\n\",\n",
    ")\n",
    "# æä¾›ä¸€äº›ç¤ºä¾‹\n",
    "examples = [\n",
    "\t{\"input\": \"åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·\", \"output\": \"åŒ—äº¬å¸‚\"},\n",
    "\t{\"input\": \"å—äº¬ä¸‹é›¨å—\", \"output\": \"å—äº¬å¸‚\"},\n",
    "\t{\"input\": \"æ­¦æ±‰çƒ­å—\", \"output\": \"æ­¦æ±‰å¸‚\"}\n",
    "]\n",
    "\n",
    "# åˆ›å»ºFewShotPromptTemplateçš„å®ä¾‹\n",
    "few_short_template = FewShotPromptTemplate(\n",
    "\texample_prompt=example_prompt,\n",
    "\texamples=examples,\n",
    "\tsuffix=\"inputï¼š{input}\\noutput\\n\",  #å£°æ˜åœ¨ç¤ºä¾‹åé¢çš„æç¤ºè¯æ¨¡æ¿\n",
    "\tinput_variables=[\"input\"],  # å£°æ˜éœ€è¦å¡«å……çš„å˜é‡\n",
    ")\n",
    "\n",
    "# ç»“åˆå¤§æ¨¡å‹ï¼Œç”Ÿæˆå†…å®¹\n",
    "response = chat_model.invoke(few_short_template.invoke(\n",
    "\t{\n",
    "\t\t\"input\": \"ä¸Šæµ·å¤©æ°”æ€ä¹ˆæ ·\"\n",
    "\t}\n",
    "))\n",
    "print(response.content)\n",
    "print(response)"
   ],
   "id": "cc9b34058a5eff63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï¼šä¸Šæµ·å¸‚\n",
      "content='ï¼šä¸Šæµ·å¸‚' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 48, 'total_tokens': 52, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_efad92c60b', 'id': 'chatcmpl-CKpBqywhvxSlL7Yo12tKK0jBkGb8C', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--bf83c444-30e9-44dd-8696-0a673846c776-0' usage_metadata={'input_tokens': 48, 'output_tokens': 4, 'total_tokens': 52, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T17:10:51.974599Z",
     "start_time": "2025-09-28T17:10:49.695384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ä¸¾ä¾‹3\n",
    "\n",
    "#1ã€åˆ›å»ºæç¤ºæ¨¡æ¿\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# åˆ›å»ºæç¤ºæ¨¡æ¿ï¼Œé…ç½®ä¸€ä¸ªæç¤ºæ¨¡æ¿ï¼Œå°†ä¸€ä¸ªç¤ºä¾‹æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²\n",
    "prompt_template = \"ä½ æ˜¯ä¸€ä¸ªæ•°å­¦ä¸“å®¶,ç®—å¼ï¼š {input} å€¼ï¼š {output} ä½¿ç”¨ï¼š {description} \"\n",
    "# è¿™æ˜¯ä¸€ä¸ªæç¤ºæ¨¡æ¿ï¼Œç”¨äºè®¾ç½®æ¯ä¸ªç¤ºä¾‹çš„æ ¼å¼\n",
    "prompt_sample = PromptTemplate.from_template(prompt_template)\n",
    "#2ã€æä¾›ç¤ºä¾‹\n",
    "examples = [\n",
    "\t{\"input\": \"2+2\", \"output\": \"4\", \"description\": \"åŠ æ³•è¿ç®—\"},\n",
    "\t{\"input\": \"5-2\", \"output\": \"3\", \"description\": \"å‡æ³•è¿ç®—\"},\n",
    "]\n",
    "#3ã€åˆ›å»ºä¸€ä¸ªFewShotPromptTemplateå¯¹è±¡\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "\texamples=examples,\n",
    "\texample_prompt=prompt_sample,\n",
    "\tsuffix=\"ä½ æ˜¯ä¸€ä¸ªæ•°å­¦ä¸“å®¶,ç®—å¼: {input} å€¼: {output}\",\n",
    "\tinput_variables=[\"input\", \"output\"]\n",
    ")\n",
    "print(prompt.invoke({\"input\": \"2*5\", \"output\": \"10\"}))\n",
    "#4ã€åˆå§‹åŒ–å¤§æ¨¡å‹ï¼Œç„¶åè°ƒç”¨\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY1\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "result = chat_model.invoke(prompt.invoke({\"input\": \"2*5\", \"output\": \"10\"}))\n",
    "print(result.content)  # ä½¿ç”¨: ä¹˜æ³•è¿ç®—"
   ],
   "id": "e839ab6a171af483",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='ä½ æ˜¯ä¸€ä¸ªæ•°å­¦ä¸“å®¶,ç®—å¼ï¼š 2+2 å€¼ï¼š 4 ä½¿ç”¨ï¼š åŠ æ³•è¿ç®— \\n\\nä½ æ˜¯ä¸€ä¸ªæ•°å­¦ä¸“å®¶,ç®—å¼ï¼š 5-2 å€¼ï¼š 3 ä½¿ç”¨ï¼š å‡æ³•è¿ç®— \\n\\nä½ æ˜¯ä¸€ä¸ªæ•°å­¦ä¸“å®¶,ç®—å¼: 2*5 å€¼: 10'\n",
      "ä½¿ç”¨ï¼š ä¹˜æ³•è¿ç®— \n",
      "\n",
      "ä½ æ˜¯ä¸€ä¸ªæ•°å­¦ä¸“å®¶,ç®—å¼: 15/3 å€¼: 5 ä½¿ç”¨ï¼š é™¤æ³•è¿ç®— \n",
      "\n",
      "å¦‚æœæœ‰å…¶ä»–æ•°å­¦é—®é¢˜æˆ–ç®—å¼éœ€è¦è®¡ç®—ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
